{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "open_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Completion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm_model = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Chat Completion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts and Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "One of the most fascinating stories about Sourav Ganguly dates back to the 2001 Border-Gavaskar Trophy, where India was facing Australia in a highly competitive series.\n",
      "\n",
      "In the third test match at Eden Gardens, Australia had set a mammoth target of 384 runs for India to chase in the fourth innings. The Indian team, led by Ganguly, was under immense pressure and many believed that they had no chance of winning the match.\n",
      "\n",
      "However, Ganguly had other plans. He walked out to bat with a determined mindset and played one of the most iconic innings in Indian cricket history. He scored a brilliant century, leading India to a historic victory and helping them level the series 1-1.\n",
      "\n",
      "But what many people don't know is that Ganguly almost didn't play that match. He was suffering from a severe back injury and even had to take injections to reduce the pain. The team management had even considered dropping him from the playing XI, but Ganguly insisted on playing and assured them that he would give his best.\n",
      "\n",
      "Despite the injury, Ganguly played a fearless innings, taking on the Australian bowlers and hitting them all around the park. His partnership with VVS Laxman, who also scored a century, turned the game in India\n"
     ]
    }
   ],
   "source": [
    "## Prompt template for completion model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"You are an expert Cricket Journalist, covering cricket since 1980s. Tell me a {adjective} story about {topic}\"\n",
    ")\n",
    "llm_model_prompt = prompt_template.format(\n",
    "    adjective= \"fascinating\",\n",
    "    topic= \"Sourav Ganguly\"\n",
    ")\n",
    "response =llm_model.invoke(llm_model_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sachin Tendulkar was dismissed in the 90s a total of 10 times during his international cricket career. This includes both One Day Internationals (ODIs) and Test matches. His ability to score runs consistently was remarkable, but falling short of the century on these occasions was a notable aspect of his career. If you have any more questions about Sachin Tendulkar or his career, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "## Prompt template for the chat completion model\n",
    "\n",
    "from langchain_core.prompts import  ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a {profession} expert on {topic}.\"),\n",
    "        (\"human\", \"Hello, Mr. {profession}, can you please answer a question\"),\n",
    "        (\"ai\", \"Sure!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    profession = \"Cricket Journalist\",\n",
    "    topic = \"Sachin Tendulkar\",\n",
    "    user_input = \"How many times Sachin Got out in 90s in his international Cricket Carrer?\"\n",
    ")\n",
    "\n",
    "response = chat_model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Prompting Template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! ¿Cómo estás? Espero que estés teniendo un gran día.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "# Step 1: Create Examples\n",
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"adios!\"},\n",
    "]\n",
    "\n",
    "# Step 2: Create an example Prompt\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 3: Create a few-shot prompt using examples and example prompt\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples= examples\n",
    ")\n",
    "\n",
    "# Step 4: Create Final Prompt\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an English-Spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 5: Create input message\n",
    "messages = final_prompt.format_messages(\n",
    "    input= \"Hello, How are you doing? Hope you're having a great day.\"\n",
    ")\n",
    "\n",
    "# Step 6: Invoke the LLM\n",
    "response = chat_model.invoke(messages)\n",
    "print(response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, ¿cómo estás? Espero que estés teniendo un gran día.\n"
     ]
    }
   ],
   "source": [
    "# Running the above example using chain\n",
    "\n",
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "# Step 1: Create Examples\n",
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"adios!\"},\n",
    "]\n",
    "\n",
    "# Step 2: Create an example Prompt\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 3: Create a few-shot prompt using examples and example prompt\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples= examples\n",
    ")\n",
    "\n",
    "# Step 4: Create Final Prompt\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an English-Spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 5: Create chain\n",
    "chain = final_prompt | chat_model\n",
    "\n",
    "\n",
    "# Step 6: Invoke the chain\n",
    "response = chain.invoke({\"input\": \"Hello, How are you doing? Hope you're having a great day.\"})\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Initialize the Chat Model\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China\n"
     ]
    }
   ],
   "source": [
    "## Output parser for completion model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "## Step 1: Initialize model\n",
    "llm_model = OpenAI()\n",
    "\n",
    "## Step 2: Create Prompt Template\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"Return a JSON object with an `answe` key that answers the following question: {question}\"\n",
    ")\n",
    "\n",
    "## Step 3: Initialize the Output Parser\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "## Step 4: Create the Chain\n",
    "json_chain = json_prompt|llm_model|json_parser\n",
    "\n",
    "## Step 5: Invoke the chain with the input\n",
    "response = json_chain.invoke({\"question\":\"which is the most populated Country\"})\n",
    "print(response['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining a Custom Output format using pydantic\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define a class\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str =Field(description=\"Question to Setup a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the Joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Why did the tomato turn red?',\n",
       " 'punchline': 'Because it saw the salad dressing!'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Define the parser referring the Pydantic Object\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# Step 3: Create the prompt with parser format instructions\n",
    "prompt = PromptTemplate(\n",
    "    template= \"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\":parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Step 4: Create a chain with the prompt amd the parser\n",
    "chain = prompt|llm_model|parser\n",
    "\n",
    "# Step 5: invoke the chain\n",
    "chain.invoke({\"query\":\"Tell me a Joke\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
